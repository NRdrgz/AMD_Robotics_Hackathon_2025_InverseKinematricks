{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQUk3Y0WwYZ4"
   },
   "source": [
    "# Train Models Using LeRobot on MI300x\n",
    "\n",
    "This guide walks you through setting up environment for training imitation learning policies using LeRobot library on a DigitalOcean (DO) instance equipped with AMD MI300x GPUs and ROCm.\n",
    "\n",
    "## ‚öôÔ∏è Requirements\n",
    "- A Hugging Face dataset repo ID containing your training data (`--dataset.repo_id=${HF_USER}/${DATASET_NAME}`).\n",
    "  If you don‚Äôt have an access token yet, you can sign up for Hugging Face [here](https://huggingface.co/join). After signing up, create an access token by visiting [here](https://huggingface.co/settings/tokens).\n",
    "- A wandb account to enable training visualization and upload your training evidence to our github.\n",
    "  You can sign up for Wandb [here](https://wandb.ai/signup) and visit [here](https://wandb.ai/authorize) to create a token.\n",
    "- Access to DO instance AMD Mi300x GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOJyX0CnwA5m"
   },
   "source": [
    "## Verify ROCm and GPU availability\n",
    "This cell uses `pytorch` to check AMD GPU Info. The expected ouput is \n",
    "```\n",
    "CUDA compatible device availability: True\n",
    "device name [0]: AMD Instinct MI300X VF\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f'CUDA compatible device availability:',torch.cuda.is_available())\n",
    "print(f'device name [0]:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOJyX0CnwA5m"
   },
   "source": [
    "## Install FFmpeg 7.x\n",
    "This cell uses `apt` to install ffmpeg 7.x for LeRobot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlKjL1X5t_zM",
    "outputId": "3b375aa1-19ed-4811-ff76-0afd5b762992",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!add-apt-repository ppa:ubuntuhandbook1/ffmpeg7 -y # install PPA which contains ffmpeg 7.x\n",
    "!apt update && apt install ffmpeg -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxCc3CARwUjN"
   },
   "source": [
    "## Install LeRobot v0.4.1\n",
    "This cell clones the `lerobot` repository from Hugging Face, and installs the package in editable mode. Extra Features: To install additional dependencies for training SmolVLA or Pi models, refer to the [LeRobot offical page](https://huggingface.co/docs/lerobot/index). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgLu7QT5tUik",
    "outputId": "e46913b8-1977-48a5-a851-d8c69602419a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/lerobot.git\n",
    "!cd lerobot && git checkout -b v0.4.1 v0.4.1 # let‚Äôs synchronize using this version\n",
    "!cd lerobot && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8Sn2wG4wldo"
   },
   "source": [
    "## Weights & Biases login\n",
    "This cell install and log into Weights & Biases (wandb) to enable experiment tracking and logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PolVM_movEvp",
    "outputId": "1769c6bd-8644-4b65-84c7-4f020b234c92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login(key=\"wandb_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login into Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PolVM_movEvp",
    "outputId": "1769c6bd-8644-4b65-84c7-4f020b234c92"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"hf_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install smolvla\n",
    "!cd lerobot && pip install -e \".[smolvla]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Recorded Datasets & Models in HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check datasets existence\n",
    "from huggingface_hub import HfApi, login, list_repo_tree\n",
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"giacomoran/hackathon_amd_mission2_blue_pick\"\n",
    "\n",
    "# Method 1: List episode files from the repo structure\n",
    "print(\"üìÅ Episode files in dataset:\")\n",
    "api = HfApi()\n",
    "for item in list_repo_tree(repo_id=repo_id, repo_type=\"dataset\", recursive=True):\n",
    "    if \"episode\" in item.path.lower() or item.path.endswith(\".parquet\"):\n",
    "        print(f\"  {item.path}\")\n",
    "\n",
    "# Method 2: Load dataset and check episode info\n",
    "print(\"\\nüìä Loading dataset metadata...\")\n",
    "dataset = load_dataset(repo_id, split=\"train\")\n",
    "\n",
    "# Check for episode column\n",
    "if \"episode_index\" in dataset.column_names:\n",
    "    episodes = sorted(set(dataset[\"episode_index\"]))\n",
    "    print(f\"\\n‚úÖ Found {len(episodes)} episodes:\")\n",
    "    for ep in episodes:\n",
    "        ep_data = dataset.filter(lambda x: x[\"episode_index\"] == ep)\n",
    "        print(f\"  Episode {ep}: {len(ep_data)} frames\")\n",
    "else:\n",
    "    print(f\"\\nDataset columns: {dataset.column_names}\")\n",
    "    print(f\"Total rows: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "# Check model existence\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Get your username automatically\n",
    "user_info = api.whoami()\n",
    "username = user_info[\"name\"]\n",
    "\n",
    "repo_id = f\"{username}/hackathon_amd_mission2_black_sort_smolvla_v4\"\n",
    "\n",
    "if api.repo_exists(repo_id=repo_id, repo_type=\"model\"):\n",
    "    print(f\"‚úÖ Model exists: https://huggingface.co/{repo_id}\")\n",
    "    # List uploaded files\n",
    "    for f in api.list_repo_files(repo_id):\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkzTo4mNwxaC"
   },
   "source": [
    "## Start Training Models with LeRobot\n",
    "\n",
    "This cell uses the lerobot-train CLI from the lerobot library to train a robot control policy.  \n",
    "\n",
    "Make sure to adjust the following arguments to your setup:\n",
    "\n",
    "1. `--dataset.repo_id=YOUR_HF_USERNAME/YOUR_DATASET`:  \n",
    "   Replace this with the Hugging Face Hub repo ID where your dataset is stored, e.g., `lerobot/svla_so100_pickplace`.\n",
    "\n",
    "2. `--policy.type=act`:  \n",
    "   Specifies the policy configuration to use. `act` refers to [configuration_act.py](../lerobot/common/policies/act/configuration_act.py), which will automatically adapt to your dataset‚Äôs setup (e.g., number of motors and cameras).\n",
    "\n",
    "3. `--output_dir=outputs/train/...`:  \n",
    "   Directory where training logs and model checkpoints will be saved.\n",
    "\n",
    "4. `--job_name=...`:  \n",
    "   A name for this training job, used for logging and Weights & Biases.The name typically includes the model type (e.g., act, smolvla), the dataset name, and additional descriptive tags.\n",
    "\n",
    "5. `--policy.device=cuda`:  \n",
    "   Use `cuda` if training on an AMD or NVIDIA GPU. \n",
    "\n",
    "6. `--wandb.enable=true`:  \n",
    "   Enables Weights & Biases for visualizing training progress. You must be logged in via `wandb login` before running this.\n",
    "\n",
    "7. `--policy.push_to_hub=`:\n",
    "\n",
    "   Enables automatic uploading of the trained policy to the Hugging Face Hub. You must specify `--policy.repo_id` (e.g., ${HF_USER}/{REPO_NAME}) if it is True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lerobot Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACT: hackathon_amd_mission2_blue_pick_act_cardboard_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lerobot-train \\\n",
    "  --dataset.repo_id=giacomoran/hackathon_amd_mission2_blue_pick_cardboard \\\n",
    "  --batch_size=64 \\\n",
    "  --steps=4000 \\\n",
    "  --output_dir=outputs/train/hackathon_amd_mission2_blue_pick_act_cardboard_v2 \\\n",
    "  --job_name=hackathon_amd_mission2_blue_pick_act_cardboard_v2 \\\n",
    "  --policy.repo_id=giacomoran/hackathon_amd_mission2_blue_pick_act_cardboard_v2 \\\n",
    "  --policy.device=cuda \\\n",
    "  --policy.path=giacomoran/hackathon_amd_mission2_blue_pick_act_cardboard \\\n",
    "  --policy.push_to_hub=true \\\n",
    "  --wandb.enable=true \\\n",
    "  --policy.chunk_size=30 \\\n",
    "  --policy.n_action_steps=30 \\\n",
    "  --optimizer.lr=5e-5 \\\n",
    "  --policy.optimizer_lr=5e-5 \\\n",
    "  --policy.optimizer_lr_backbone=5e-5 \\\n",
    "  --save_freq=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli upload hackathon_amd_mission2_blue_pick_act_cardboard_v2 \\\n",
    "  outputs/train/hackathon_amd_mission2_blue_pick_act_cardboard_v2/checkpoints/last/pretrained_model \\\n",
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOLVLA: hackathon_amd_mission2_black_flip_smolvla_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lerobot-train \\\n",
    "  --dataset.repo_id=giacomoran/hackathon_amd_mission2_black_flip \\\n",
    "  --rename_map='{\"observation.images.top\": \"observation.images.camera1\", \"observation.images.wrist\": \"observation.images.camera2\"}' \\\n",
    "  --policy.empty_cameras=1 \\\n",
    "  --policy.load_vlm_weights=true \\\n",
    "  --policy.prefix_length=-1 \\\n",
    "  --policy.pad_language_to=longest \\\n",
    "  --policy.num_expert_layers=-1 \\\n",
    "  --batch_size=32 \\\n",
    "  --steps=80000 \\\n",
    "  --output_dir=outputs/train/hackathon_amd_mission2_black_flip_smolvla_v3 \\\n",
    "  --job_name=hackathon_amd_mission2_black_flip_smolvla_v3 \\\n",
    "  --policy.repo_id=giacomoran/hackathon_amd_mission2_black_flip_smolvla_v3 \\\n",
    "  --policy.device=cuda \\\n",
    "  --policy.path=lerobot/smolvla_base \\\n",
    "  --policy.push_to_hub=true \\\n",
    "  --wandb.enable=true \\\n",
    "  --policy.chunk_size=30 \\\n",
    "  --policy.n_action_steps=30 \\\n",
    "  --save_freq=20000 \\\n",
    "  --optimizer.lr=1e-3 \\\n",
    "  --optimizer.betas=[0.9,0.999] \\\n",
    "  --optimizer.weight_decay=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli upload hackathon_amd_mission2_black_flip_smolvla_v3 \\\n",
    "  outputs/train/hackathon_amd_mission2_black_flip_smolvla_v3/checkpoints/last/pretrained_model \\\n",
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOLVLA: hackathon_amd_mission2_black_sort_smolvla_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lerobot-train \\\n",
    "  --dataset.repo_id=giacomoran/hackathon_amd_mission2_black_sort_fixed \\\n",
    "  --rename_map='{\"observation.images.top\": \"observation.images.camera1\", \"observation.images.wrist\": \"observation.images.camera2\"}' \\\n",
    "  --policy.empty_cameras=1 \\\n",
    "  --policy.load_vlm_weights=true \\\n",
    "  --policy.prefix_length=-1 \\\n",
    "  --policy.pad_language_to=longest \\\n",
    "  --policy.num_expert_layers=-1 \\\n",
    "  --batch_size=32 \\\n",
    "  --steps=12000 \\\n",
    "  --output_dir=outputs/train/hackathon_amd_mission2_black_sort_smolvla_v4 \\\n",
    "  --job_name=hackathon_amd_mission2_black_sort_smolvla_v4 \\\n",
    "  --policy.repo_id=giacomoran/hackathon_amd_mission2_black_sort_smolvla_v4 \\\n",
    "  --policy.device=cuda \\\n",
    "  --policy.path=giacomoran/hackathon_amd_mission2_black_sort_smolvla_v3 \\\n",
    "  --policy.push_to_hub=true \\\n",
    "  --wandb.enable=true \\\n",
    "  --policy.chunk_size=30 \\\n",
    "  --policy.n_action_steps=30 \\\n",
    "  --save_freq=20000 \\\n",
    "  --optimizer.lr=5e-4 \\\n",
    "  --optimizer.betas=[0.9,0.999] \\\n",
    "  --optimizer.weight_decay=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli upload hackathon_amd_mission2_black_sort_smolvla_v4 \\\n",
    "  outputs/train/hackathon_amd_mission2_black_sort_smolvla_v4/checkpoints/last/pretrained_model \\\n",
    "  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "\n",
    "- If using a local dataset, add `--dataset.root=/path/to/dataset`.\n",
    "- Adjust `--batch_size` and `--steps` based on your hardware and dataset.\n",
    "- Model checkpoints, logs, and training plots will be saved to the specified `--output_dir`\n",
    "- Training progress visualized in your wandb dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models from Hugging Face to Local Machine\n",
    "Now after training is done, download the model to local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFMLGuVkH7UN",
    "outputId": "535f0717-4d6b-4eeb-beee-25416f7af383"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli download ${HF_USER}/{REPO_NAME} --repo-type model --local-dir path/to/model\n",
    "# e.g. huggingface-cli upload ${HF_USER}/act_so101_3cube_1ksteps \\\n",
    "#  outputs/train/act_so101_3cube_1ksteps/checkpoints/last/pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscs\n",
    "1. Once the environment is setup, you can open a terminal session for training by navigating to `File ‚Üí New Launcher ‚Üí Other ‚Üí Terminal`.\n",
    "2. You can also upload your datasets to the container by clicking the `Upload Files` button in the left pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "1. If you encounter an error like:\n",
    "   ```\n",
    "   FileExistsError: Output directory outputs/train/act_so101_3cube_1ksteps already exists and resume is False. Please change your output directory so that outputs/train/act_so101_3cube_1ksteps is not overwritten. \n",
    "   ```\n",
    "   Remove the existing directory before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFMLGuVkH7UN",
    "outputId": "535f0717-4d6b-4eeb-beee-25416f7af383"
   },
   "outputs": [],
   "source": [
    "!rm -fr outputs/train/act_so101_3cube_1ksteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. When running models other than ACT, ensure you install the required additional dependencies for those models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For smolVLA\n",
    "!cd lerobot && pip install -e \".[smolvla]\"\n",
    "# For Pi\n",
    "!cd lerobot && pip install -e \".[pi]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. If you want to resume the training from last checkpoint, run the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lerobot-train \\\n",
    "  --resume=true \\\n",
    "  --config_path=outputs/train/<job name>/checkpoints/last/pretrained_model/train_config.json \\\n",
    "  --steps=<new total steps>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If you want to upload your dataset using `huggingface-cli upload <repo name> <path to the dataset> --repo-type=dataset`, be sure to set a codebase tag like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"your_huggingface_token\")\n",
    "hub_api = HfApi()\n",
    "hub_api.create_tag(<HF_REPO_NAME>, tag=\"v3.0\", revision=\"main\", repo_type=\"dataset\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
